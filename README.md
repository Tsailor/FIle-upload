大文件上传前端部分代码
功能：
1 文件切片 使用MD5计算hash值
2 并发上传控制
3 文件断点续传、秒传

实现思路：
后端使用的是MinIO，对每个片有一定的大小限制
前端需要根据文件的大小去分片，并使用MD5计算文件的hash值。然后将每片大小、分片数量、hash值提交给后端。
后端会返回 缺失的片与上传这些片的url 
这里是三种情况 1.文件没传过，返回所有的片 2.部分上传，返回缺失的片 需要断点续传 3.已经传过，返回空，直接文件秒传

前端拿到缺失的片与上传这些片的url后，开始并发上传，需要实现并发上传控制。
所有的片上传完毕后，通知后端去合并这些片 （MinIo的限制，不清楚其他的文件服务是否需要这样）

需要优化的内容：
超大文件 hash计算时间过长问题
链接：https://juejin.cn/post/6986188684605259783
一开始是借鉴 React中Fiber的实现，将计算hash值的过程使用requestIdleCallback进行改进，发现文件太大了的话还是会卡顿很久。最终，我们打算使用抽样思路来计算hash，放弃一部的准确度来换取时间
思路：设置一个小一点的大小比如 2M

我们在计算hash的时候，将超大文件以2M进行分割获得到另一个chunks数组，
第一个元素(chunks[0])和最后一个元素(chunks[-1])我们全要了
其他的元素(chunks[1,2,3,4....])我们再次进行一个分割，这个时候的分割是一个超小的大小比如2kb，我们取每一个元素的头部，尾部，中间的2kb。
最终将它们组成一个新的文件，我们全量计算这个新的文件的hash值。

